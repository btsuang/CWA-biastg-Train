{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404effbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from darts import TimeSeries\n",
    "from darts.models import ExponentialSmoothing\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.metrics import mape, mae, rmse\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def mbe(y_true, y_pred):\n",
    "    return np.mean(y_true - y_pred)\n",
    "\n",
    "folder_path = 'SeaData\\\\csv\\\\d10'\n",
    "date = 'd10'\n",
    "\n",
    "with open(f\"Statistics for Time Series III - ETS-Itterative {date}.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([f'Statistics for Time Series III - ETS-Itterative {date}'])\n",
    "    \n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        print(f'Processing file: {file_path}')\n",
    "        tag = ''\n",
    "        if 'dbiastg' in file_name:\n",
    "            tag = 'dbiastg'\n",
    "        else:\n",
    "            tag = 'biastg'   \n",
    "        writer.writerow([file_name])       \n",
    "\n",
    "        data = pd.read_csv(file_path, index_col='date', parse_dates=True)\n",
    "\n",
    "        # Prepare the data\n",
    "        data = data[tag]\n",
    "        data = data.asfreq('B').fillna(method='ffill')  # Fill missing values\n",
    "\n",
    "        # Create a TimeSeries object\n",
    "        ts = TimeSeries.from_dataframe(data.reset_index(), 'date', tag)\n",
    "\n",
    "        # Normalize the dataset\n",
    "        scaler = Scaler()\n",
    "        ts_scaled = scaler.fit_transform(ts)\n",
    "\n",
    "        # Calculate the split date for 80% of the data\n",
    "        split_date = data.index[int(0.8 * len(data))]\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        train_ts, test_ts = ts_scaled.split_after(split_date)\n",
    "\n",
    "        # Create and fit the ETS model\n",
    "        model = ExponentialSmoothing()\n",
    "        model.fit(train_ts)\n",
    "\n",
    "        # Make predictions\n",
    "        predicted_ts = model.predict(len(test_ts))\n",
    "\n",
    "        # Invert scaling\n",
    "        predicted_ts_unscaled = scaler.inverse_transform(predicted_ts)\n",
    "        test_ts_unscaled = scaler.inverse_transform(test_ts)\n",
    "\n",
    "        # Evaluate the model\n",
    "        print(\"RMSE: {:.2f}\".format(rmse(test_ts_unscaled, predicted_ts_unscaled)))\n",
    "        writer.writerow(['RMSE',rmse(test_ts_unscaled, predicted_ts_unscaled)])\n",
    "        print(\"MAE: {:.2f}\".format(mae(test_ts_unscaled, predicted_ts_unscaled)))\n",
    "        writer.writerow(['MAE',mae(test_ts_unscaled, predicted_ts_unscaled)])\n",
    "        print(\"MBE: {:.2f}\".format(mbe(test_ts_unscaled.values(), predicted_ts_unscaled.values())))\n",
    "        writer.writerow(['MBE',mbe(test_ts_unscaled.values(), predicted_ts_unscaled.values())])\n",
    "        print(\"MAPE: {:.2f}%\".format(mape(test_ts_unscaled, predicted_ts_unscaled)))\n",
    "        writer.writerow(['MAPE',mape(test_ts_unscaled, predicted_ts_unscaled)])\n",
    "\n",
    "\n",
    "\n",
    "        # Plot the results\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        ts.plot(label='Observed')\n",
    "        predicted_ts_unscaled.plot(color='r', label='Predicted')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel(tag)\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30527c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.models import ExponentialSmoothing\n",
    "from darts.backtesting import (\n",
    "    backtest_forecasting,\n",
    "    plot_residuals_analysis,\n",
    ")\n",
    "\n",
    "# Additional imports\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define ETS model types\n",
    "ets_model_types = [('add', 'add', 'add', None),\n",
    "                   ('mul', 'add', 'add', None),\n",
    "                   ('add', 'add', 'mul', None),\n",
    "                   ('mul', 'add', 'mul', None)]\n",
    "\n",
    "# Initialize minimum error and best model\n",
    "min_error = float('inf')\n",
    "best_model = None\n",
    "best_model_type = None\n",
    "\n",
    "# Loop through ETS model types\n",
    "for model_type in ets_model_types:\n",
    "    print(f\"Trying ETS model with error type: {model_type}\")\n",
    "\n",
    "    # Create the ETS model\n",
    "    model = ExponentialSmoothing(*model_type)\n",
    "\n",
    "    # Use rolling window to create multiple training and testing sets and backtest the model\n",
    "    errors = backtest_forecasting(ts_scaled,\n",
    "                                  model,\n",
    "                                  pd.Timestamp(split_date),\n",
    "                                  fcast_horizon_n=1,  # 1-step ahead forecasting\n",
    "                                  verbose=True)\n",
    "\n",
    "    # Calculate the mean error\n",
    "    mean_error = np.mean(errors)\n",
    "\n",
    "    # Check if the current model has a lower error than the previous models\n",
    "    if mean_error < min_error:\n",
    "        min_error = mean_error\n",
    "        best_model = model\n",
    "        best_model_type = model_type\n",
    "\n",
    "print(f\"Best ETS model: {best_model_type} with mean error: {min_error}\")\n",
    "\n",
    "# Fit the best model on the training set\n",
    "best_model.fit(train_ts)\n",
    "\n",
    "# Make predictions\n",
    "predicted_ts = best_model.predict(len(test_ts))\n",
    "\n",
    "# Invert scaling\n",
    "predicted_ts_unscaled = scaler.inverse_transform(predicted_ts)\n",
    "test_ts_unscaled = scaler.inverse_transform(test_ts)\n",
    "\n",
    "# Evaluate the best model\n",
    "print(\"RMSE: {:.2f}\".format(rmse(test_ts_unscaled, predicted_ts_unscaled)))\n",
    "print(\"MAE: {:.2f}\".format(mae(test_ts_unscaled, predicted_ts_unscaled)))\n",
    "print(\"MBE: {:.2f}\".format(mbe(test_ts_unscaled.values(), predicted_ts_unscaled.values())))\n",
    "print(\"MAPE: {:.2f}%\".format(mape(test_ts_unscaled, predicted_ts_unscaled)))\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(14, 6))\n",
    "ts.plot(label='Observed')\n",
    "predicted_ts_unscaled.plot(color='r', label='Predicted')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel(tag)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
