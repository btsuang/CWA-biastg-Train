{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a4248bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install netCDF4 pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c522018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import netCDF4 as nc\n",
    "\n",
    "def create_folder_if_not_exists(folder_path):\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "        print(f\"Created folder: {folder_path}\")\n",
    "    else:\n",
    "        print(f\"Folder already exists: {folder_path}\")\n",
    "\n",
    "def netcdf_to_csv(input_folder, output_folder):\n",
    "    # Get a list of all NetCDF files in the input folder\n",
    "    files = [f for f in os.listdir(input_folder) if f.endswith('.nc')]\n",
    "    \n",
    "    create_folder_if_not_exists(output_folder)\n",
    "\n",
    "    # Process each NetCDF file\n",
    "    for file in files:\n",
    "        # Read NetCDF file\n",
    "        dataset = nc.Dataset(os.path.join(input_folder, file))\n",
    "\n",
    "        # Convert variables to separate DataFrames based on dimensions\n",
    "        data_frames = []\n",
    "        for var_name, variable in dataset.variables.items():\n",
    "            if variable.size == 0:  # Skip variables with no data\n",
    "                continue\n",
    "\n",
    "            dims = variable.dimensions\n",
    "            key = ','.join(dims)\n",
    "            data = {var_name: variable[:].flatten()}\n",
    "            df_var = pd.DataFrame(data)\n",
    "            data_frames.append(df_var)\n",
    "\n",
    "        # Concatenate DataFrames, matching columns based on their names\n",
    "        df = pd.concat(data_frames, axis=1)\n",
    "\n",
    "        # Write DataFrame to CSV file        \n",
    "        output_filename = os.path.splitext(file)[0] + '.csv'\n",
    "        output_path = os.path.join(output_folder, output_filename)\n",
    "        df.to_csv(output_path, index=False)\n",
    "\n",
    "        print(f'Processed {file} -> {output_filename}')\n",
    "\n",
    "# Replace these paths with the input and output folders you want to use\n",
    "input_folder = 'SeaData/NetCDF'\n",
    "output_folder = 'SeaData/csv'\n",
    "\n",
    "netcdf_to_csv(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c92ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import netCDF4 as nc\n",
    "\n",
    "input_file = 'SeaData/NetCDF/S_tau10d_seagrid.nc'\n",
    " # Read NetCDF file\n",
    "dataset = nc.Dataset(input_file)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba0cf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy\n",
    "import xarray\n",
    "import csv\n",
    "\n",
    "input_file = 'SeaData/NetCDF/S_tau10d_seagrid.nc'\n",
    "dsub = xarray.open_dataset(input_file)\n",
    "print(dsub)\n",
    "print(dsub)\n",
    "lat = len(dsub['lat'].values)\n",
    "lon = len(dsub['lon'].values)\n",
    "time = len(dsub['time'].values)\n",
    "biastg = len(dsub['dbiastg'].values)\n",
    "print(lat)\n",
    "print(lon)\n",
    "print(time)\n",
    "print(biastg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1a67ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import ma\n",
    "from matplotlib import pyplot as plt\n",
    "# from mpl_toolkits.basemap import Basemap as bm\n",
    "\n",
    "# from eofs.standard import Eof\n",
    "\n",
    "input_folder = 'SeaData/NetCDF/'\n",
    "dpath = os.path.join(input_folder)\n",
    "print(dpath)\n",
    "\n",
    "\n",
    "######################\n",
    "#load the SST data\n",
    "######################\n",
    "import xarray\n",
    "#print(xarray.__version__)\n",
    "\n",
    "ncfname = os.path.join(dpath,'S_tau10d_seagrid.nc')\n",
    "dset = xarray.open_dataset(ncfname)\n",
    "print(dset.head(5))\n",
    "print(dset)\n",
    "print(dset.lat)\n",
    "\n",
    "##############################################################\n",
    "#selects the period 1980-2014 and the tropical Pacific domain\n",
    "##############################################################\n",
    "dsub = dset.sel(time=slice('2021','2021'), lat=slice(-40,40,-1), lon=slice(120,290))\n",
    "lat = dset['lat'].values\n",
    "print(lat)\n",
    "lon = dset['lon'].values\n",
    "sst = dset['dbiastg'].values.squeeze() # because of zlev\n",
    "print(sst.shape)\n",
    "print(sst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1b4060",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyproj -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae326b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install basemap-1.3.3-cp310-cp310-win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91b9464a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data variables:\n",
      "dbiastg: <xarray.DataArray 'dbiastg' (time: 516, lat: 73, lon: 144)>\n",
      "[5424192 values with dtype=float32]\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 2021-01-11 2021-01-12 ... 2022-06-10\n",
      "  * lon      (lon) float32 0.0 2.5 5.0 7.5 10.0 ... 350.0 352.5 355.0 357.5\n",
      "  * lat      (lat) float32 -90.0 -87.5 -85.0 -82.5 -80.0 ... 82.5 85.0 87.5 90.0\n",
      "Attributes:\n",
      "    long_name:  SST\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "\n",
    "# Replace this path with the path to your NetCDF file\n",
    "netcdf_file = 'SeaData/NetCDF/S_tau10d_seagrid.nc'\n",
    "\n",
    "# Open the NetCDF file as an xarray.Dataset\n",
    "dataset = xr.open_dataset(netcdf_file)\n",
    "\n",
    "# Access the data variables\n",
    "data_variables = dataset.data_vars\n",
    "\n",
    "# Print the data variables\n",
    "print(\"Data variables:\")\n",
    "for var_name, variable in data_variables.items():\n",
    "    print(f\"{var_name}: {variable}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046a28d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def create_folder_if_not_exists(folder_path):\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "        print(f\"Created folder: {folder_path}\")\n",
    "    else:\n",
    "        print(f\"Folder already exists: {folder_path}\")\n",
    "\n",
    "# Replace this path with the path to your NetCDF file\n",
    "netcdf_file = \"SeaData/NetCDF/S_tau10d_seagrid.nc\"\n",
    "\n",
    "# Replace this path with the path to your output folder\n",
    "output_folder = \"SeaData/csv\"\n",
    "\n",
    "# Open the NetCDF file as an xarray.Dataset/csv\n",
    "dataset = xr.open_dataset(netcdf_file)\n",
    "\n",
    "# Select the 'dbiastg' variable\n",
    "dbiastg = dataset['dbiastg']\n",
    "\n",
    "create_folder_if_not_exists(output_folder)\n",
    "\n",
    "# Create a CSV file for each unique 'lat' and 'lon' pair\n",
    "for lat_value in dbiastg.lat.values:\n",
    "    for lon_value in dbiastg.lon.values:\n",
    "        # Get 'dbiastg' values at the specified lat and lon\n",
    "        dbiastg_values = dbiastg.sel(lat=lat_value, lon=lon_value)\n",
    "\n",
    "        # Create a DataFrame with 'time' and 'dbiastg' values\n",
    "        data = {'time': dbiastg.time.values, 'dbiastg': dbiastg_values.values}\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        # Save the DataFrame to a CSV file\n",
    "        output_filename = f\"dbiastg_lat_{lat_value}_lon_{lon_value}.csv\"\n",
    "        output_path = os.path.join(output_folder, output_filename)\n",
    "        df.to_csv(output_path, index=False)\n",
    "\n",
    "        print(f\"Created {output_filename} with {len(df)} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a9228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# path NetCDF file\n",
    "netcdf_file = \"SeaData/NetCDF/S_tau10d_seagrid.nc\"\n",
    "\n",
    "# path to output folder\n",
    "output_folder = \"SeaData/csv2\"\n",
    "\n",
    "\n",
    "# Open the NetCDF file as an xarray.Dataset\n",
    "dataset = xr.open_dataset(netcdf_file)\n",
    "\n",
    "# Select the 'dbiastg' variable\n",
    "dbiastg = dataset['dbiastg']\n",
    "\n",
    "create_folder_if_not_exists(output_folder)\n",
    "\n",
    "# Replace NaN values in 'dbiastg' using numpy.interp for each unique 'lat' and 'lon' pair\n",
    "for lat_value in dbiastg.lat.values:\n",
    "    for lon_value in dbiastg.lon.values:\n",
    "        # Get 'dbiastg' values at the specified lat and lon\n",
    "        dbiastg_values = dbiastg.sel(lat=lat_value, lon=lon_value)\n",
    "\n",
    "        # Get non-NaN indices and values for 'time' and 'dbiastg'\n",
    "        non_nan_indices = np.isfinite(dbiastg_values.values)\n",
    "        non_nan_time_values = dbiastg_values.time[non_nan_indices].values\n",
    "        non_nan_dbiastg_values = dbiastg_values.values[non_nan_indices]\n",
    "\n",
    "        if non_nan_dbiastg_values.size > 0:\n",
    "            # Interpolate 'dbiastg' values using numpy.interp\n",
    "            interpolated_dbiastg_values = np.interp(dbiastg_values.time.values, non_nan_time_values, non_nan_dbiastg_values)\n",
    "\n",
    "            # Replace the original 'dbiastg' values with the interpolated values\n",
    "            dbiastg.loc[dict(lat=lat_value, lon=lon_value)] = interpolated_dbiastg_values\n",
    "        else:\n",
    "            print(f\"No non-NaN values available for lat={lat_value}, lon={lon_value}\")\n",
    "        \n",
    "        # Create a DataFrame with 'time' and 'dbiastg' values\n",
    "        data = {'time': dbiastg.time.values, 'dbiastg': dbiastg_values.values}\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        # Save the DataFrame to a CSV file\n",
    "        output_filename = f\"dbiastg_lat_{lat_value}_lon_{lon_value}.csv\"\n",
    "        output_path = os.path.join(output_folder, output_filename)\n",
    "        df.to_csv(output_path, index=False)\n",
    "\n",
    "        print(f\"Created {output_filename} with {len(df)} rows\")\n",
    "\n",
    "print(\"Finished replacing NaN values in 'dbiastg' using numpy.interp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09e7a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
