{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24aa639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7b9e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import os\n",
    "import csv\n",
    "\n",
    "\n",
    "# Function to calculate Mean Absolute Percentage Error (MAPE)\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Function to prepare the dataset for LSTM\n",
    "def create_dataset(dataset, look_back=1, time_steps=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - time_steps - look_back + 1):\n",
    "        a = dataset[i:(i + time_steps * look_back), 0].reshape(time_steps, look_back)\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i + time_steps * look_back - 1, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "# Learning rate scheduler function\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * 0.9  # Reduce learning rate after 10 epochs\n",
    "\n",
    "# Function to build the LSTM model\n",
    "def build_lstm_model(units=64, dropout_rate=0.2, time_steps=3, look_back=1):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, return_sequences=True, input_shape=(time_steps, look_back)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(units // 2, return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(units // 4))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam())\n",
    "    return model\n",
    "\n",
    "folder_path = 'SeaData\\\\csv\\\\d10'\n",
    "date = 'd10'\n",
    "\n",
    "# Hyperparameter search space\n",
    "param_grid = {\n",
    "    'units': [32, 64, 128],\n",
    "    'dropout_rate': [0.2, 0.3, 0.5],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [50, 100],\n",
    "    'time_steps': [3, 5],  # Number of time steps\n",
    "}\n",
    "\n",
    "# Prepare CSV output for logging results\n",
    "with open(f\"Statistics for LSTM Hyperparameter Tuning {date}.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([f'Statistics for LSTM Hyperparameter Tuning {date}'])\n",
    "    \n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        print(f'Processing file: {file_path}')\n",
    "        tag = ''\n",
    "        if 'dbiastg' in file_name:\n",
    "            tag = 'dbiastg'\n",
    "        else:\n",
    "            tag = 'biastg'   \n",
    "        writer.writerow([file_name])       \n",
    "\n",
    "        data = pd.read_csv(file_path, index_col='date', parse_dates=True)\n",
    "\n",
    "        # Prepare the data\n",
    "        data = data[tag]\n",
    "        data = data.asfreq('B').fillna(method='ffill')  # Fill missing values\n",
    "\n",
    "        # Normalize the dataset\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        data = scaler.fit_transform(data.values.reshape(-1, 1))\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        train_size = int(len(data) * 0.8)\n",
    "        test_size = len(data) - train_size\n",
    "        train_data, test_data = data[0:train_size,:], data[train_size:len(data),:]\n",
    "\n",
    "        # Reshape the data into X=t and Y=t+time_steps\n",
    "        look_back = 1\n",
    "        time_steps = 3  # Increase the number of time steps\n",
    "        X_train, Y_train = create_dataset(train_data, look_back, time_steps)\n",
    "        X_test, Y_test = create_dataset(test_data, look_back, time_steps)\n",
    "\n",
    "        # Reshape the input to be [samples, time steps, features]\n",
    "        X_train = np.reshape(X_train, (X_train.shape[0], time_steps, look_back))\n",
    "        X_test = np.reshape(X_test, (X_test.shape[0], time_steps, look_back))\n",
    "\n",
    "        # Hyperparameter tuning using RandomizedSearchCV\n",
    "        model = KerasRegressor(build_fn=build_lstm_model, verbose=0)\n",
    "        random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=5, cv=3, verbose=2, random_state=42)\n",
    "        random_search.fit(X_train, Y_train)\n",
    "\n",
    "        best_params = random_search.best_params_\n",
    "        print(f\"Best hyperparameters: {best_params}\")\n",
    "\n",
    "        # Create the final model with best hyperparameters\n",
    "        best_model = build_lstm_model(units=best_params['units'], dropout_rate=best_params['dropout_rate'], time_steps=time_steps, look_back=look_back)\n",
    "        \n",
    "        # Implement EarlyStopping and Learning Rate Scheduler\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "        lr_scheduler = LearningRateScheduler(scheduler)\n",
    "\n",
    "        # Train the model\n",
    "        best_model.fit(X_train, Y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=2, validation_data=(X_test, Y_test), callbacks=[early_stopping, lr_scheduler])\n",
    "\n",
    "        # Make predictions\n",
    "        train_predict = best_model.predict(X_train)\n",
    "        test_predict = best_model.predict(X_test)\n",
    "\n",
    "        # Invert predictions\n",
    "        train_predict = scaler.inverse_transform(train_predict)\n",
    "        Y_train = scaler.inverse_transform([Y_train])\n",
    "        test_predict = scaler.inverse_transform(test_predict)\n",
    "        Y_test = scaler.inverse_transform([Y_test])\n",
    "\n",
    "        # Evaluate the model\n",
    "        mae = mean_absolute_error(Y_test[0], test_predict[:,0])\n",
    "        mse = mean_squared_error(Y_test[0], test_predict[:,0])\n",
    "        rmse = np.sqrt(mse)\n",
    "        mbe = np.mean(Y_test[0] - test_predict[:,0])\n",
    "        mape = mean_absolute_percentage_error(Y_test[0], test_predict[:,0])\n",
    "\n",
    "        print(f\"RMSE: {rmse:.2f}\")\n",
    "        writer.writerow(['RMSE', rmse])\n",
    "        print(f\"MAE: {mae:.2f}\")\n",
    "        writer.writerow(['MAE', mae])\n",
    "        print(f\"MBE: {mbe:.2f}\")\n",
    "        writer.writerow(['MBE', mbe])\n",
    "        print(f\"MAPE: {mape:.2f}%\")\n",
    "        writer.writerow(['MAPE', mape])\n",
    "\n",
    "        # Plot the results\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        plt.plot(data, label='Observed')\n",
    "        plt.plot(np.concatenate((train_predict, test_predict)), color='r', label='Predicted')\n",
    "        plt.title(f'Observed vs Predicted for {file_name}')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel(tag)\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
