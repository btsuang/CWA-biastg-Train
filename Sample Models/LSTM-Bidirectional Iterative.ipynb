{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24aa639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import os\n",
    "import csv\n",
    "\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def create_dataset(dataset, look_back=1, time_steps=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - time_steps - look_back + 1):\n",
    "        a = dataset[i:(i + time_steps * look_back), 0].reshape(time_steps, look_back)\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i + time_steps * look_back - 1, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "\n",
    "folder_path = 'SeaData\\\\csv\\\\d10'\n",
    "date = 'd10'\n",
    "\n",
    "with open(f\"Statistics for LSTM l3n {date}.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([f'Statistics for LSTM {date}'])\n",
    "    \n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        print(f'Processing file: {file_path}')\n",
    "        tag = ''\n",
    "        if 'dbiastg' in file_name:\n",
    "            tag = 'dbiastg'\n",
    "        else:\n",
    "            tag = 'biastg'   \n",
    "        writer.writerow([file_name])       \n",
    "\n",
    "        data = pd.read_csv(file_path, index_col='date', parse_dates=True)\n",
    "\n",
    "        # Prepare the data\n",
    "        data = data[tag]\n",
    "        data = data.asfreq('B').fillna(method='ffill')  # Fill missing values\n",
    "\n",
    "        # Normalize the dataset\n",
    "        scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        data = scaler.fit_transform(data.values.reshape(-1, 1))\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        train_size = int(len(data) * 0.8)\n",
    "        test_size = len(data) - train_size\n",
    "        train_data, test_data = data[0:train_size,:], data[train_size:len(data),:]\n",
    "\n",
    "        # Reshape the data into X=t and Y=t+time_steps\n",
    "        look_back = 1\n",
    "        time_steps = 3  # Increase the number of time steps\n",
    "        X_train, Y_train = create_dataset(train_data, look_back, time_steps)\n",
    "        X_test, Y_test = create_dataset(test_data, look_back, time_steps)\n",
    "\n",
    "        # Reshape the input to be [samples, time steps, features]\n",
    "        X_train = np.reshape(X_train, (X_train.shape[0], time_steps, look_back))\n",
    "        X_test = np.reshape(X_test, (X_test.shape[0], time_steps, look_back))\n",
    "\n",
    "        # Create and fit the Bidirectional LSTM network with additional hidden layers\n",
    "        model = Sequential()\n",
    "        model.add(Bidirectional(LSTM(64, return_sequences=True, input_shape=(time_steps, look_back))))\n",
    "        model.add(Dropout(0.2))  # Add dropout layer\n",
    "        model.add(Bidirectional(LSTM(32, return_sequences=True)))  # Add second Bidirectional LSTM layer\n",
    "        model.add(Dropout(0.2))  # Add dropout layer\n",
    "        model.add(Bidirectional(LSTM(16)))  # Add third Bidirectional LSTM layer\n",
    "        model.add(Dropout(0.2))  # Add dropout layer\n",
    "        model.add(Dense(1))\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        model.fit(X_train, Y_train, epochs=100, batch_size=1, verbose=2)\n",
    "        \n",
    "        # Make predictions\n",
    "        train_predict = model.predict(X_train)\n",
    "        test_predict = model.predict(X_test)\n",
    "\n",
    "        # Invert predictions\n",
    "        train_predict = scaler.inverse_transform(train_predict)\n",
    "        Y_train = scaler.inverse_transform([Y_train])\n",
    "        test_predict = scaler.inverse_transform(test_predict)\n",
    "        Y_test = scaler.inverse_transform([Y_test])\n",
    "\n",
    "        # Evaluate the model\n",
    "        mae = mean_absolute_error(Y_test[0], test_predict[:,0])\n",
    "        mse = mean_squared_error(Y_test[0], test_predict[:,0])\n",
    "        rmse = np.sqrt(mse)\n",
    "        mbe = np.mean(Y_test[0] - test_predict[:,0])\n",
    "        mape = mean_absolute_percentage_error(Y_test[0], test_predict[:,0])\n",
    "\n",
    "        print(f\"RMSE: {rmse:.2f}\")\n",
    "        writer.writerow(['RMSE',rmse])\n",
    "        print(f\"MAE: {mae:.2f}\")\n",
    "        writer.writerow(['MAE',mae])\n",
    "        print(f\"MBE: {mbe:.2f}\")\n",
    "        writer.writerow(['MBE',mbe])\n",
    "        print(f\"MAPE: {mape:.2f}%\")\n",
    "        writer.writerow(['MAPE',mape])\n",
    "\n",
    "        # Plot the results\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        plt.plot(data, label='Observed')\n",
    "        plt.plot(np.concatenate((train_predict, test_predict)), color='r', label='Predicted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7b9e74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
