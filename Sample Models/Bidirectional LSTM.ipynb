{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae28e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import os\n",
    "import csv\n",
    "\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def create_dataset(dataset, look_back=1, time_steps=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - time_steps - look_back + 1):\n",
    "        a = dataset[i:(i + time_steps * look_back), 0].reshape(time_steps, look_back)\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i + time_steps * look_back - 1, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "def extract_lat_lon(filename):\n",
    "    lat_str = filename.split(\"lat_\")[1].split(\"_\")[0]\n",
    "    lon_str = filename.split(\"lon_\")[1].split(\".\")[0]\n",
    "    lat = float(lat_str)\n",
    "    lon = float(lon_str)\n",
    "    return lat, lon\n",
    "\n",
    "\n",
    "folder_path = 'Replace the folder with the csv files'\n",
    "date = 'This is the date string Ex: For Day10: d10'\n",
    "\n",
    "# Following is the output csv file \n",
    "with open(f\"Statistics for LSTM {date}.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([f'Statistics for LSTM {date}'])\n",
    "    \n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        print(f'Processing file: {file_path}')\n",
    "        tag = ''\n",
    "        if 'dbiastg' in file_name:\n",
    "            tag = 'dbiastg'\n",
    "        else:\n",
    "            tag = 'biastg'   \n",
    "        \n",
    "        writer.writerow([file_name])   \n",
    "        latitude, longitude = extract_lat_lon(file_name)\n",
    "        writer.writerow(['latitude',latitude])\n",
    "        writer.writerow(['longitude',longitude])\n",
    "        data = pd.read_csv(file_path, index_col='date', parse_dates=True)\n",
    "        data = data[tag]\n",
    "                \n",
    "        if data.notnull().any():  # Proceed if there's at least one non-null value\n",
    "            # Prepare the data\n",
    "            data = data.asfreq('B').fillna(method='ffill')  # Fill missing values\n",
    "            data = data.dropna()\n",
    "            # Normalize the dataset\n",
    "            scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "            data = scaler.fit_transform(data.values.reshape(-1, 1))\n",
    "\n",
    "            # Split the data into training and testing sets\n",
    "            train_size = int(len(data) * 0.8)\n",
    "            test_size = len(data) - train_size\n",
    "            train_data, test_data = data[0:train_size,:], data[train_size:len(data),:]\n",
    "\n",
    "            # Reshape the data into X=t and Y=t+time_steps\n",
    "            look_back = 1\n",
    "            time_steps = 3  # Increase the number of time steps\n",
    "            X_train, Y_train = create_dataset(train_data, look_back, time_steps)\n",
    "            X_test, Y_test = create_dataset(test_data, look_back, time_steps)\n",
    "\n",
    "            # Reshape the input to be [samples, time steps, features]\n",
    "            X_train = np.reshape(X_train, (X_train.shape[0], time_steps, look_back))\n",
    "            X_test = np.reshape(X_test, (X_test.shape[0], time_steps, look_back))\n",
    "\n",
    "            # Create and fit the Bidirectional LSTM network with additional hidden layers\n",
    "            model = Sequential()\n",
    "            model.add(Bidirectional(LSTM(64, return_sequences=True, input_shape=(time_steps, look_back))))\n",
    "            model.add(Dropout(0.2))  # Add dropout layer\n",
    "            model.add(Bidirectional(LSTM(32, return_sequences=True)))  # Add second Bidirectional LSTM layer\n",
    "            model.add(Dropout(0.2))  # Add dropout layer\n",
    "            model.add(Bidirectional(LSTM(16)))  # Add third Bidirectional LSTM layer\n",
    "            model.add(Dropout(0.2))  # Add dropout layer\n",
    "            model.add(Dense(1))\n",
    "            model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "            model.fit(X_train, Y_train, epochs=100, batch_size=1, verbose=2)\n",
    "\n",
    "            # Make predictions\n",
    "            train_predict = model.predict(X_train)\n",
    "            test_predict = model.predict(X_test)\n",
    "\n",
    "            # Invert predictions\n",
    "            train_predict = scaler.inverse_transform(train_predict)\n",
    "            Y_train = scaler.inverse_transform([Y_train])\n",
    "            test_predict = scaler.inverse_transform(test_predict)\n",
    "            Y_test = scaler.inverse_transform([Y_test])\n",
    "\n",
    "            # Evaluate the model\n",
    "            mae = mean_absolute_error(Y_test[0], test_predict[:,0])\n",
    "            mse = mean_squared_error(Y_test[0], test_predict[:,0])\n",
    "            rmse = np.sqrt(mse)\n",
    "            mbe = np.mean(Y_test[0] - test_predict[:,0])\n",
    "            mape = mean_absolute_percentage_error(Y_test[0], test_predict[:,0])\n",
    "\n",
    "            print(f\"RMSE: {rmse:.2f}\")\n",
    "            writer.writerow(['RMSE',rmse])\n",
    "            print(f\"MAE: {mae:.2f}\")\n",
    "            writer.writerow(['MAE',mae])\n",
    "            print(f\"MBE: {mbe:.2f}\")\n",
    "            writer.writerow(['MBE',mbe])\n",
    "            print(f\"MAPE: {mape:.2f}%\")\n",
    "            writer.writerow(['MAPE',mape])\n",
    "\n",
    "            # Plot the results\n",
    "            plt.figure(figsize=(14, 6))\n",
    "            plt.plot(data, label='Observed')\n",
    "            plt.plot(np.concatenate((train_predict, test_predict)), color='r', label='Predicted')\n",
    "        else:\n",
    "            print(f'Skipping file {file_name} due to no non-null values in {tag} column.')\n",
    "            continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ccedb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Bidirectional, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Function to calculate Mean Absolute Percentage Error (MAPE)\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Function to prepare the dataset for LSTM\n",
    "def create_dataset(dataset, look_back=1, time_steps=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset) - time_steps - look_back + 1):\n",
    "        a = dataset[i:(i + time_steps * look_back), 0].reshape(time_steps, look_back)\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i + time_steps * look_back - 1, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "# Learning rate scheduler function\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * 0.9  # Reduce learning rate after 10 epochs\n",
    "\n",
    "# Function to build the LSTM model\n",
    "def build_lstm_model(units=64, dropout_rate=0.2, time_steps=3, look_back=1):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, return_sequences=True, input_shape=(time_steps, look_back)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(units // 2, return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(units // 4))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam())\n",
    "    return model\n",
    "\n",
    "folder_path = 'Replace the folder with the csv files'\n",
    "date = 'This is the date string Ex: For Day10: d10'\n",
    "\n",
    "# Hyperparameter search space\n",
    "param_grid = {\n",
    "    'units': [32, 64, 128],\n",
    "    'dropout_rate': [0.2, 0.3, 0.5],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'epochs': [50, 100],\n",
    "    'time_steps': [3, 5],  # Number of time steps\n",
    "}\n",
    "\n",
    "# Prepare CSV output for logging results\n",
    "with open(f\"Statistics for LSTM Hyperparameter Tuning {date}.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([f'Statistics for LSTM Hyperparameter Tuning {date}'])\n",
    "    \n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        print(f'Processing file: {file_path}')\n",
    "        tag = ''\n",
    "        if 'dbiastg' in file_name:\n",
    "            tag = 'dbiastg'\n",
    "        else:\n",
    "            tag = 'biastg'   \n",
    "        \n",
    "        writer.writerow([file_name])   \n",
    "        data = pd.read_csv(file_path, index_col='time', parse_dates=True)\n",
    "        data = data[tag]\n",
    "                \n",
    "        if data.notnull().any():  # Proceed if there's at least one non-null value\n",
    "            # Prepare the data\n",
    "            data = data.asfreq('B').fillna(method='ffill')  # Fill missing values\n",
    "            data = data.dropna()\n",
    "            # Normalize the dataset\n",
    "            scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "            data = scaler.fit_transform(data.values.reshape(-1, 1))\n",
    "\n",
    "            # Split the data into training and testing sets\n",
    "            train_size = int(len(data) * 0.8)\n",
    "            test_size = len(data) - train_size\n",
    "            train_data, test_data = data[0:train_size,:], data[train_size:len(data),:]\n",
    "\n",
    "            # Reshape the data into X=t and Y=t+time_steps\n",
    "            look_back = 1\n",
    "            time_steps = 3  # Increase the number of time steps\n",
    "            X_train, Y_train = create_dataset(train_data, look_back, time_steps)\n",
    "            X_test, Y_test = create_dataset(test_data, look_back, time_steps)\n",
    "\n",
    "            # Reshape the input to be [samples, time steps, features]\n",
    "            X_train = np.reshape(X_train, (X_train.shape[0], time_steps, look_back))\n",
    "            X_test = np.reshape(X_test, (X_test.shape[0], time_steps, look_back))\n",
    "\n",
    "            # Hyperparameter tuning using RandomizedSearchCV\n",
    "            model = KerasRegressor(build_fn=build_lstm_model, verbose=0)\n",
    "            random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=5, cv=3, verbose=2, random_state=42)\n",
    "            random_search.fit(X_train, Y_train)\n",
    "\n",
    "            best_params = random_search.best_params_\n",
    "            print(f\"Best hyperparameters: {best_params}\")\n",
    "\n",
    "            # Create the final model with best hyperparameters\n",
    "            best_model = build_lstm_model(units=best_params['units'], dropout_rate=best_params['dropout_rate'], time_steps=time_steps, look_back=look_back)\n",
    "            \n",
    "            # Implement EarlyStopping and Learning Rate Scheduler\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "            lr_scheduler = LearningRateScheduler(scheduler)\n",
    "\n",
    "            # Train the model\n",
    "            best_model.fit(X_train, Y_train, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=2, validation_data=(X_test, Y_test), callbacks=[early_stopping, lr_scheduler])\n",
    "\n",
    "            # Make predictions\n",
    "            train_predict = best_model.predict(X_train)\n",
    "            test_predict = best_model.predict(X_test)\n",
    "\n",
    "            # Invert predictions\n",
    "            train_predict = scaler.inverse_transform(train_predict)\n",
    "            Y_train = scaler.inverse_transform([Y_train])\n",
    "            test_predict = scaler.inverse_transform(test_predict)\n",
    "            Y_test = scaler.inverse_transform([Y_test])\n",
    "\n",
    "            # Evaluate the model\n",
    "            mae = mean_absolute_error(Y_test[0], test_predict[:,0])\n",
    "            mse = mean_squared_error(Y_test[0], test_predict[:,0])\n",
    "            rmse = np.sqrt(mse)\n",
    "            mbe = np.mean(Y_test[0] - test_predict[:,0])\n",
    "            mape = mean_absolute_percentage_error(Y_test[0], test_predict[:,0])\n",
    "\n",
    "            print(f\"RMSE: {rmse:.2f}\")\n",
    "            writer.writerow(['RMSE', rmse])\n",
    "            print(f\"MAE: {mae:.2f}\")\n",
    "            writer.writerow(['MAE', mae])\n",
    "            print(f\"MBE: {mbe:.2f}\")\n",
    "            writer.writerow(['MBE', mbe])\n",
    "            print(f\"MAPE: {mape:.2f}%\")\n",
    "            writer.writerow(['MAPE', mape])\n",
    "\n",
    "            # Plot the results\n",
    "            plt.figure(figsize=(14, 6))\n",
    "            plt.plot(data, label='Observed')\n",
    "            plt.plot(np.concatenate((train_predict, test_predict)), color='r', label='Predicted')\n",
    "            plt.title(f'Observed vs Predicted for {file_name}')\n",
    "            plt.xlabel('Date')\n",
    "            plt.ylabel(tag)\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f'Skipping file {file_name} due to no non-null values in {tag} column.')\n",
    "            continue\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
