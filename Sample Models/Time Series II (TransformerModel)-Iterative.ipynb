{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b779b09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from darts import TimeSeries\n",
    "from darts.models import TransformerModel\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.metrics import mape, mae, rmse\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def mbe(y_true, y_pred):\n",
    "    return np.mean(y_true - y_pred)\n",
    "\n",
    "folder_path = 'SeaData\\\\csv\\\\d10'\n",
    "date = 'd10'\n",
    "\n",
    "with open(f\"Statistics for Time Series II Transformer {date}.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([f'Statistics for Time Series II Transformer {date}'])\n",
    "    \n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        print(f'Processing file: {file_path}')\n",
    "        tag = ''\n",
    "        if 'dbiastg' in file_name:\n",
    "            tag = 'dbiastg'\n",
    "        else:\n",
    "            tag = 'biastg'   \n",
    "        writer.writerow([file_name])       \n",
    "\n",
    "        data = pd.read_csv(file_path, index_col='date', parse_dates=True)\n",
    "\n",
    "        # Prepare the data\n",
    "        data = data[tag]\n",
    "        data = data.asfreq('B').fillna(method='ffill')  # Fill missing values\n",
    "\n",
    "        # Create a TimeSeries object\n",
    "        ts = TimeSeries.from_dataframe(data.reset_index(), 'date', tag)\n",
    "\n",
    "        # Normalize the dataset\n",
    "        scaler = Scaler()\n",
    "        ts_scaled = scaler.fit_transform(ts)\n",
    "\n",
    "        # Calculate the split date for 80% of the data\n",
    "        split_date = data.index[int(0.8 * len(data))]\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        train_ts, test_ts = ts_scaled.split_after(split_date)\n",
    "\n",
    "        # Create and fit the Time Series Transformer model\n",
    "        model = TransformerModel(input_chunk_length=12, output_chunk_length=1, n_epochs=50)\n",
    "        model.fit(train_ts)\n",
    "\n",
    "        # Make predictions\n",
    "        predicted_ts = model.predict(len(test_ts))\n",
    "\n",
    "        # Invert scaling\n",
    "        predicted_ts_unscaled = scaler.inverse_transform(predicted_ts)\n",
    "        test_ts_unscaled = scaler.inverse_transform(test_ts)\n",
    "\n",
    "\n",
    "        # Evaluate the model\n",
    "        # Evaluate the model\n",
    "#         mbe = mbe(test_ts_unscaled.values(), predicted_ts_unscaled.values())\n",
    "\n",
    "        print(\"RMSE: {:.2f}\".format(rmse(test_ts_unscaled, predicted_ts_unscaled)))\n",
    "        writer.writerow(['RMSE',rmse(test_ts_unscaled, predicted_ts_unscaled)])\n",
    "        print(\"MAE: {:.2f}\".format(mae(test_ts_unscaled, predicted_ts_unscaled)))\n",
    "        writer.writerow(['MAE',mae(test_ts_unscaled, predicted_ts_unscaled)])\n",
    "#         print(\"MBE: {:.2f}\".format(mbe(test_ts_unscaled.values(), predicted_ts_unscaled.values())))\n",
    "#         writer.writerow(['MBE',mbe])\n",
    "        print(\"MAPE: {:.2f}%\".format(mape(test_ts_unscaled, predicted_ts_unscaled)))\n",
    "        writer.writerow(['MAPE',mape(test_ts_unscaled, predicted_ts_unscaled)])\n",
    "\n",
    "\n",
    "        # Plot the results\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        ts.plot(label='Observed')\n",
    "        predicted_ts_unscaled.plot(color='r', label='Predicted')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('biastg')\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43702348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from darts import TimeSeries\n",
    "from darts.models import TransformerModel\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.metrics import mape, mae, rmse\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def mbe(y_true, y_pred):\n",
    "    return np.mean(y_true - y_pred)\n",
    "\n",
    "folder_path = 'SeaData\\\\csv\\\\d10'\n",
    "date = 'd10'\n",
    "\n",
    "with open(f\"Statistics for Time Series II Transformer {date}.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([f'Statistics for Time Series II Transformer {date}'])\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        print(f'Processing file: {file_path}')\n",
    "        tag = ''\n",
    "        if 'dbiastg' in file_name:\n",
    "            tag = 'dbiastg'\n",
    "        else:\n",
    "            tag = 'biastg'\n",
    "        writer.writerow([file_name])\n",
    "\n",
    "        data = pd.read_csv(file_path, index_col='date', parse_dates=True)\n",
    "\n",
    "        # Prepare the data\n",
    "        data = data[tag]\n",
    "        data = data.asfreq('B').fillna(method='ffill')  # Fill missing values\n",
    "\n",
    "        # Create a TimeSeries object\n",
    "        ts = TimeSeries.from_dataframe(data.reset_index(), 'date', tag)\n",
    "\n",
    "        # Normalize the dataset\n",
    "        scaler = Scaler()\n",
    "        ts_scaled = scaler.fit_transform(ts)\n",
    "\n",
    "        # Calculate the split date for 80% of the data\n",
    "        split_date = data.index[int(0.8 * len(data))]\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        train_ts, test_ts = ts_scaled.split_after(split_date)\n",
    "\n",
    "        # Create and fit the Time Series Transformer model\n",
    "        model = TransformerModel(input_chunk_length=24, output_chunk_length=1, n_epochs=100)  # Increase input_chunk_length and n_epochs\n",
    "        model.fit(train_ts)\n",
    "\n",
    "        # Make predictions\n",
    "        predicted_ts = model.predict(len(test_ts))\n",
    "\n",
    "        # Invert scaling\n",
    "        predicted_ts_unscaled = scaler.inverse_transform(predicted_ts)\n",
    "        test_ts_unscaled = scaler.inverse_transform(test_ts)\n",
    "\n",
    "        # Evaluate the model\n",
    "        print(\"RMSE: {:.2f}\".format(rmse(test_ts_unscaled, predicted_ts_unscaled)))\n",
    "        writer.writerow(['RMSE', rmse(test_ts_unscaled, predicted_ts_unscaled)])\n",
    "        print(\"MAE: {:.2f}\".format(mae(test_ts_unscaled, predicted_ts_unscaled)))\n",
    "        writer.writerow(['MAE', mae(test_ts_unscaled, predicted_ts_unscaled)])\n",
    "        print(\"MAPE: {:.2f}%\".format(mape(test_ts_unscaled, predicted_ts_unscaled)))\n",
    "        writer.writerow(['MAPE', mape(test_ts_unscaled, predicted_ts_unscaled)])\n",
    "\n",
    "        # Plot the results\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        ts.plot(label='Observed')\n",
    "        predicted_ts_unscaled.plot(color='r', label='Predicted')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('biastg')\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
